{
    "nbformat_minor": 1, 
    "cells": [
        {
            "execution_count": 138, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 138, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "[Row(mpg='18', cylinders='8', displacement='307', horsepower='130', weight='3504', acceleration='12', model_year='70'),\n Row(mpg='15', cylinders='8', displacement='350', horsepower='165', weight='3693', acceleration='11.5', model_year='70'),\n Row(mpg='18', cylinders='8', displacement='318', horsepower='150', weight='3436', acceleration='11', model_year='70'),\n Row(mpg='16', cylinders='8', displacement='304', horsepower='150', weight='3433', acceleration='12', model_year='70'),\n Row(mpg='17', cylinders='8', displacement='302', horsepower='140', weight='3449', acceleration='10.5', model_year='70')]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "# The code was removed by Watson Studio for sharing."
        }, 
        {
            "execution_count": 72, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#convert to integer & double\n\nfrom pyspark.sql.types import IntegerType\nfrom pyspark.sql.types import DoubleType\n\nautompg_df=autompg_df.withColumn(\"mpg\", autompg_df[\"mpg\"].cast(IntegerType()))\nautompg_df=autompg_df.withColumn(\"cylinders\", autompg_df[\"cylinders\"].cast(IntegerType()))\nautompg_df=autompg_df.withColumn(\"displacement\", autompg_df[\"displacement\"].cast(IntegerType()))\nautompg_df=autompg_df.withColumn(\"horsepower\", autompg_df[\"horsepower\"].cast(IntegerType()))\nautompg_df=autompg_df.withColumn(\"weight\", autompg_df[\"weight\"].cast(IntegerType()))\nautompg_df=autompg_df.withColumn(\"acceleration\", autompg_df[\"acceleration\"].cast(DoubleType()))\nautompg_df=autompg_df.withColumn(\"model_year\", autompg_df[\"model_year\"].cast(IntegerType()))"
        }, 
        {
            "execution_count": 73, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "root\n |-- mpg: integer (nullable = true)\n |-- cylinders: integer (nullable = true)\n |-- displacement: integer (nullable = true)\n |-- horsepower: integer (nullable = true)\n |-- weight: integer (nullable = true)\n |-- acceleration: double (nullable = true)\n |-- model_year: integer (nullable = true)\n\n"
                }
            ], 
            "source": "#print schema to check data type\n\nautompg_df.cache()\nautompg_df.printSchema()"
        }, 
        {
            "execution_count": 74, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 74, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>summary</th>\n      <td>count</td>\n      <td>mean</td>\n      <td>stddev</td>\n      <td>min</td>\n      <td>max</td>\n    </tr>\n    <tr>\n      <th>mpg</th>\n      <td>392</td>\n      <td>23.283163265306122</td>\n      <td>7.745895518598281</td>\n      <td>9</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>cylinders</th>\n      <td>392</td>\n      <td>5.471938775510204</td>\n      <td>1.7057832474527845</td>\n      <td>3</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>displacement</th>\n      <td>392</td>\n      <td>194.41071428571428</td>\n      <td>104.64519123492178</td>\n      <td>68</td>\n      <td>455</td>\n    </tr>\n    <tr>\n      <th>horsepower</th>\n      <td>392</td>\n      <td>104.46938775510205</td>\n      <td>38.49115993282846</td>\n      <td>46</td>\n      <td>230</td>\n    </tr>\n    <tr>\n      <th>weight</th>\n      <td>392</td>\n      <td>2977.5841836734694</td>\n      <td>849.4025600429486</td>\n      <td>1613</td>\n      <td>5140</td>\n    </tr>\n    <tr>\n      <th>acceleration</th>\n      <td>392</td>\n      <td>15.541326530612228</td>\n      <td>2.75886411918808</td>\n      <td>8.0</td>\n      <td>24.8</td>\n    </tr>\n    <tr>\n      <th>model_year</th>\n      <td>392</td>\n      <td>75.9795918367347</td>\n      <td>3.683736543577868</td>\n      <td>70</td>\n      <td>82</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "                  0                   1                   2     3     4\nsummary       count                mean              stddev   min   max\nmpg             392  23.283163265306122   7.745895518598281     9    46\ncylinders       392   5.471938775510204  1.7057832474527845     3     8\ndisplacement    392  194.41071428571428  104.64519123492178    68   455\nhorsepower      392  104.46938775510205   38.49115993282846    46   230\nweight          392  2977.5841836734694   849.4025600429486  1613  5140\nacceleration    392  15.541326530612228    2.75886411918808   8.0  24.8\nmodel_year      392    75.9795918367347   3.683736543577868    70    82"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "#statistik deskriptif\n\nautompg_df.describe().toPandas().transpose()"
        }, 
        {
            "execution_count": 75, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Correlation to mpg for  mpg 1.0\nCorrelation to mpg for  cylinders -0.7801431847418415\nCorrelation to mpg for  displacement -0.8067650504345276\nCorrelation to mpg for  horsepower -0.7794147299944597\nCorrelation to mpg for  weight -0.8350800096091144\nCorrelation to mpg for  acceleration 0.4237641938905716\nCorrelation to mpg for  model_year 0.5690076613980674\n"
                }
            ], 
            "source": "#find data correlation\n\nimport six\nfor i in autompg_df.columns:\n    if not( isinstance(autompg_df.select(i).take(1)[0][0], six.string_types)):\n        print( \"Correlation to mpg for \", i, autompg_df.stat.corr('mpg',i))"
        }, 
        {
            "execution_count": 76, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+--------------------+---+\n|            features|mpg|\n+--------------------+---+\n|[8.0,307.0,130.0,...| 18|\n|[8.0,350.0,165.0,...| 15|\n|[8.0,318.0,150.0,...| 18|\n+--------------------+---+\nonly showing top 3 rows\n\n"
                }
            ], 
            "source": "#mapping features and mpg\n\nfrom pyspark.ml.feature import VectorAssembler\n\nvectorAssembler = VectorAssembler(inputCols = ['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year'], outputCol = 'features')\nvhouse_df = vectorAssembler.transform(autompg_df)\nvhouse_df = vhouse_df.select(['features', 'mpg'])\nvhouse_df.show(3)"
        }, 
        {
            "execution_count": 77, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#split training to test\n\nsplits = vhouse_df.randomSplit([0.7, 0.3])\ntrain_df = splits[0]\ntest_df = splits[1]"
        }, 
        {
            "execution_count": 111, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Coefficients: [-0.0579200582013,-0.00369747009786,-0.00314446845492,-0.00579259422779,0.0,0.69412952953]\nIntercept: -10.760170895222297\n"
                }
            ], 
            "source": "#linear regression\nfrom pyspark.ml.regression import LinearRegression\n\nlr = LinearRegression(featuresCol = 'features', labelCol='mpg', maxIter=10, regParam=0.3, elasticNetParam=0.8)\nlr_model = lr.fit(train_df)\nprint(\"Coefficients: \" + str(lr_model.coefficients))\nprint(\"Intercept: \" + str(lr_model.intercept))"
        }, 
        {
            "execution_count": 112, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "RMSE: 3.453549\nr2: 0.807264\n"
                }
            ], 
            "source": "#root mean and r square\n\ntrainingSummary = lr_model.summary\nprint(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\nprint(\"r2: %f\" % trainingSummary.r2)"
        }, 
        {
            "execution_count": 113, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+-------+-----------------+\n|summary|              mpg|\n+-------+-----------------+\n|  count|              288|\n|   mean|23.35763888888889|\n| stddev|7.880236646025767|\n|    min|                9|\n|    max|               46|\n+-------+-----------------+\n\n"
                }
            ], 
            "source": "#describe data training\n\ntrain_df.describe().show()"
        }, 
        {
            "execution_count": 114, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+------------------+---+--------------------+\n|        prediction|mpg|            features|\n+------------------+---+--------------------+\n|30.005083508953724| 23|[3.0,70.0,100.0,2...|\n|26.116497266499614| 21|[3.0,80.0,110.0,2...|\n| 28.45932418340942| 29|[4.0,68.0,49.0,18...|\n|30.377226088449888| 31|[4.0,76.0,52.0,16...|\n| 31.20003760583525| 32|[4.0,78.0,52.0,19...|\n|28.500092063806214| 26|[4.0,79.0,67.0,19...|\n|29.496266544701307| 29|[4.0,85.0,52.0,20...|\n|31.797462005821835| 40|[4.0,85.0,65.0,21...|\n|30.625184373599474| 39|[4.0,85.0,70.0,20...|\n|25.765281417007465| 30|[4.0,88.0,76.0,20...|\n+------------------+---+--------------------+\nonly showing top 10 rows\n\nR Squared (R2) on test data = 0.789473\n"
                }
            ], 
            "source": "#akurasi prediksi test data\n\nlr_predictions = lr_model.transform(test_df)\nlr_predictions.select(\"prediction\",\"mpg\",\"features\").show(10)\nfrom pyspark.ml.evaluation import RegressionEvaluator\nlr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n                 labelCol=\"mpg\",metricName=\"r2\")\nprint(\"R Squared (R2) on test data = %g\" % lr_evaluator.evaluate(lr_predictions))"
        }, 
        {
            "execution_count": 115, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Root Mean Squared Error (RMSE) on test data = 3.37633\n"
                }
            ], 
            "source": "#find RMSE on the test data set\n\ntest_result = lr_model.evaluate(test_df)\nprint(\"Root Mean Squared Error (RMSE) on test data = %g\" % test_result.rootMeanSquaredError)"
        }, 
        {
            "execution_count": 116, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Root Mean Squared Error (RMSE) on test data = 3.39005\n"
                }
            ], 
            "source": "#Decision Tree\n\nfrom pyspark.ml.regression import DecisionTreeRegressor\ndt = DecisionTreeRegressor(featuresCol ='features', labelCol = 'mpg')\ndt_model = dt.fit(train_df)\ndt_predictions = dt_model.transform(test_df)\ndt_evaluator = RegressionEvaluator(\n    labelCol=\"mpg\", predictionCol=\"prediction\", metricName=\"rmse\")\nrmse = dt_evaluator.evaluate(dt_predictions)\nprint(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
        }, 
        {
            "execution_count": 118, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 118, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "SparseVector(6, {1: 0.6602, 2: 0.1826, 3: 0.0541, 4: 0.0026, 5: 0.1004})"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "#mana yang paling berpengaruh\n\ndt_model.featureImportances"
        }, 
        {
            "execution_count": 119, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 119, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "[Row(mpg=18, cylinders=8, displacement=307, horsepower=130, weight=3504, acceleration=12.0, model_year=70)]"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "autompg_df.take(1)"
        }, 
        {
            "execution_count": 120, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+------------------+---+--------------------+\n|        prediction|mpg|            features|\n+------------------+---+--------------------+\n| 32.50757655055839| 23|[3.0,70.0,100.0,2...|\n|18.946737087148758| 21|[3.0,80.0,110.0,2...|\n|30.764691275277873| 29|[4.0,68.0,49.0,18...|\n| 34.30907384961368| 31|[4.0,76.0,52.0,16...|\n|36.897961630737356| 32|[4.0,78.0,52.0,19...|\n+------------------+---+--------------------+\nonly showing top 5 rows\n\n"
                }
            ], 
            "source": "#gradient-boosted tree regression\n\nfrom pyspark.ml.regression import GBTRegressor\ngbt = GBTRegressor(featuresCol = 'features', labelCol = 'mpg', maxIter=10)\ngbt_model = gbt.fit(train_df)\ngbt_predictions = gbt_model.transform(test_df)\ngbt_predictions.select('prediction', 'mpg', 'features').show(5)"
        }, 
        {
            "execution_count": 104, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Root Mean Squared Error (RMSE) on test data = 3.23249\n"
                }
            ], 
            "source": "#Evaluate GBT\n\ngbt_evaluator = RegressionEvaluator(\n    labelCol=\"mpg\", predictionCol=\"prediction\", metricName=\"rmse\")\nrmse = gbt_evaluator.evaluate(gbt_predictions)\nprint(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
        }, 
        {
            "execution_count": 134, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "#logistic regression\nfrom pyspark.ml.classification import NaiveBayes\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\nnb = NaiveBayes(featuresCol = 'features', labelCol='mpg', smoothing=1.0, modelType=\"multinomial\")\nmodel = nb.fit(train_df)\n"
        }, 
        {
            "execution_count": 135, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "+--------------------+---+--------------------+--------------------+----------+\n|            features|mpg|       rawPrediction|         probability|prediction|\n+--------------------+---+--------------------+--------------------+----------+\n|[3.0,70.0,100.0,2...| 23|[-1259.6566725228...|[1.03651415457028...|      22.0|\n|[3.0,80.0,110.0,2...| 21|[-1349.7795926595...|[3.08234809356765...|      15.0|\n|[4.0,68.0,49.0,18...| 29|[-1034.5269489371...|[1.01285903389234...|      32.0|\n|[4.0,76.0,52.0,16...| 31|[-1028.8839394635...|[1.76150459977023...|      30.0|\n|[4.0,78.0,52.0,19...| 32|[-1108.1614003062...|[8.99310228649071...|      33.0|\n|[4.0,79.0,67.0,19...| 26|[-1118.9481798674...|[2.91582943032005...|      22.0|\n|[4.0,85.0,52.0,20...| 29|[-1141.2159114451...|[6.72989170062788...|      32.0|\n|[4.0,85.0,65.0,21...| 40|[-1193.6642129306...|[5.54400766844986...|      22.0|\n|[4.0,85.0,70.0,20...| 39|[-1193.4649265949...|[1.50810445215533...|      22.0|\n|[4.0,88.0,76.0,20...| 30|[-1168.0980192938...|[7.40994309744083...|      23.0|\n|[4.0,89.0,60.0,19...| 38|[-1169.3880602965...|[1.00166157255805...|      28.0|\n|[4.0,89.0,71.0,19...| 31|[-1169.4653518938...|[4.15389504972957...|      25.0|\n|[4.0,89.0,71.0,19...| 31|[-1177.9362892424...|[6.83573320587584...|      25.0|\n|[4.0,90.0,70.0,19...| 29|[-1153.1669466532...|[1.81614640923598...|      23.0|\n|[4.0,91.0,53.0,17...| 33|[-1102.4280051136...|[8.00490203135382...|      33.0|\n|[4.0,97.0,54.0,22...| 23|[-1198.2723866275...|[5.07079043174436...|      32.0|\n|[4.0,97.0,67.0,19...| 30|[-1191.0731645423...|[3.91531220790844...|      25.0|\n|[4.0,97.0,67.0,20...| 32|[-1225.7292293451...|[5.10754322914788...|      25.0|\n|[4.0,97.0,71.0,18...| 29|[-1157.3907472860...|[1.35225563910897...|      27.0|\n|[4.0,97.0,88.0,21...| 27|[-1237.0311226227...|[1.49965659910799...|      23.0|\n+--------------------+---+--------------------+--------------------+----------+\nonly showing top 20 rows\n\n"
                }
            ], 
            "source": "# select example rows to display.\npredictions = model.transform(test_df)\npredictions.show()"
        }, 
        {
            "execution_count": 137, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Test set accuracy = 0.009615384615384616\n"
                }
            ], 
            "source": "# compute accuracy on the test set\nevaluator = MulticlassClassificationEvaluator(labelCol=\"mpg\", predictionCol=\"prediction\",\n                                              metricName=\"accuracy\")\naccuracy = evaluator.evaluate(predictions)\nprint(\"Test set accuracy = \" + str(accuracy))"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.1", 
            "name": "python3-spark21", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.4", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}